{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4 logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_benchmarks_file1 = json.load(open(\"gpt_4/minimal/old_mix/loopy_2023_08_27_02_50_01/final_rechecked_re_filtered.json\", \"r\", encoding=\"utf-8\"))\n",
    "mix_benchmarks_file2 = json.load(open(\"gpt_4/minimal/old_mix/loopy_2023_08_17_03_55_30/final_rechecked_re_filtered.json\", \"r\", encoding=\"utf-8\"))\n",
    "diff_file = json.load(open(\"gpt_4/minimal/diff_files/loopy_2023_10_28_04_19_25/final.json\", \"r\", encoding=\"utf-8\"))\n",
    "code2inv_file = json.load(open(\"gpt_4/minimal/code2inv/loopy_2023_10_31_09_39_01/final.json\", \"r\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_json = {\n",
    "    \"params\" : {\n",
    "        \"config_file\": \"expt3.yaml\"\n",
    "    },\n",
    "    \"logs\" : [],\n",
    "    \"files_to_rerun\" : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in zip(mix_benchmarks_file1[\"logs\"], mix_benchmarks_file2[\"logs\"]):\n",
    "    if \"completions\" not in log[0] or \"completions\" not in log[1]:\n",
    "        combined_json[\"files_to_rerun\"].append(log[0][\"file\"])\n",
    "        continue\n",
    "    instance_json = {\n",
    "        \"file\" : log[0][\"file\"],\n",
    "        \"benchmark_code\" : log[0][\"benchmark_code\"],\n",
    "        \"completions\" : log[0][\"completions\"] + log[1][\"completions\"],\n",
    "        \"invariants\" : log[0][\"invariants\"] + log[1][\"invariants\"],\n",
    "        \"code_with_combined_invariants\" : \"\",\n",
    "        \"checker_output\" : None,\n",
    "    }\n",
    "\n",
    "    combined_json[\"logs\"].append(instance_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in diff_file[\"logs\"]:\n",
    "    if \"completions\" not in log:\n",
    "        combined_json[\"files_to_rerun\"].append(log[\"file\"])\n",
    "        continue\n",
    "    instance_json = {\n",
    "        \"file\" : log[\"file\"],\n",
    "        \"benchmark_code\" : log[\"benchmark_code\"],\n",
    "        # \"completions\" : log[\"completions\"],\n",
    "        \"invariants\" : log[\"annotation_blocks\"],\n",
    "        \"code_with_combined_invariants\" : log[\"code_with_combined_annotations\"],\n",
    "        \"checker_output\" : log[\"checker_output_for_combined_annotations\"],\n",
    "    }\n",
    "    completions = []\n",
    "    for completion in log[\"completions\"]:\n",
    "        completions.append({\n",
    "            \"invariants\": completion[\"annotations\"],\n",
    "            \"success\": completion[\"checker_output_for_annotations\"],\n",
    "            \"checker_message\": completion[\"checker_message_for_annotations\"],\n",
    "        })\n",
    "        if \"checker_output_after_prune\" in completion:\n",
    "            completions[-1][\"success_after_prune\"] = completion[\"checker_output_after_prune\"]\n",
    "            completions[-1][\"pruned_code\"] = completion[\"code_after_prune\"]\n",
    "    instance_json[\"completions\"] = completions\n",
    "    if \"code_after_prune\" in log:\n",
    "        instance_json[\"code_after_combine_and_prune\"] = log[\"code_after_prune\"]\n",
    "        instance_json[\"checker_output_after_combine_and_prune\"] = log[\"checker_output_after_prune\"]\n",
    "\n",
    "    combined_json[\"logs\"].append(instance_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in code2inv_file[\"logs\"]:\n",
    "    if \"completions\" not in log:\n",
    "        combined_json[\"files_to_rerun\"].append(log[\"file\"])\n",
    "        continue\n",
    "    instance_json = {\n",
    "        \"file\" : log[\"file\"],\n",
    "        \"benchmark_code\" : log[\"benchmark_code\"],\n",
    "        # \"completions\" : log[\"completions\"],\n",
    "        \"invariants\" : log[\"annotation_blocks\"],\n",
    "        \"code_with_combined_invariants\" : log[\"code_with_combined_annotations\"],\n",
    "        \"checker_output\" : log[\"checker_output_for_combined_annotations\"],\n",
    "    }\n",
    "\n",
    "    completions = []\n",
    "    for completion in log[\"completions\"]:\n",
    "        if not \"checker_output_for_annotations\" in completion:\n",
    "            completions.append({\n",
    "                \"checker_output_for_annotations\" : completion[\"success\"],\n",
    "                \"error\" : completion[\"error\"],\n",
    "                \"llm_output\" : completion[\"llm_output\"],\n",
    "            })\n",
    "            continue\n",
    "        completions.append({\n",
    "            \"invariants\": completion[\"annotations\"],\n",
    "            \"success\": completion[\"checker_output_for_annotations\"],\n",
    "            \"checker_message\": completion[\"checker_message_for_annotations\"],\n",
    "        })\n",
    "        if \"checker_output_after_prune\" in completion:\n",
    "            completions[-1][\"success_after_prune\"] = completion[\"checker_output_after_prune\"]\n",
    "            completions[-1][\"pruned_code\"] = completion[\"code_after_prune\"]\n",
    "\n",
    "    combined_json[\"logs\"].append(instance_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt_4/combined_logs_m0_prompt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With nudges prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_file = json.load(open(\"gpt_4/with_nudges/diff_files/loopy_2023_10_27_10_53_58/final.json\", \"r\", encoding=\"utf-8\"))\n",
    "code2inv_file = json.load(open(\"gpt_4/with_nudges/code2inv/loopy_2023_10_03_02_16_01/final_rechecked.json\", \"r\", encoding=\"utf-8\"))\n",
    "mix_benchmarks_file1 = json.load(open(\"gpt_4/with_nudges/old_mix/loopy_2023_08_25_13_54_09/final_rechecked_re_filtered.json\", \"r\", encoding=\"utf-8\"))\n",
    "mix_benchmarks_file2 = json.load(open(\"gpt_4/with_nudges/old_mix/loopy_2023_08_13_23_52_42/final_rechecked_rechecked_re_filtered.json\", \"r\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_json = {\n",
    "    \"params\" : {\n",
    "        \"config_file\": \"expt2.yaml\"\n",
    "    },\n",
    "    \"logs\" : [],\n",
    "    \"files_to_rerun\" : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in diff_file[\"logs\"]:\n",
    "    if \"completions\" not in log:\n",
    "        combined_json[\"files_to_rerun\"].append(log[\"file\"])\n",
    "        continue\n",
    "    instance_json = {\n",
    "        \"file\" : log[\"file\"],\n",
    "        \"benchmark_code\" : log[\"benchmark_code\"],\n",
    "        # \"completions\" : log[\"completions\"],\n",
    "        \"invariants\" : log[\"annotation_blocks\"],\n",
    "        \"code_with_combined_invariants\" : log[\"code_with_combined_annotations\"],\n",
    "        \"checker_output\" : log[\"checker_output_for_combined_annotations\"],\n",
    "    }\n",
    "    completions = []\n",
    "    for completion in log[\"completions\"]:\n",
    "        if not \"checker_output_for_annotations\" in completion:\n",
    "            completions.append({\n",
    "                \"checker_output_for_annotations\" : completion[\"success\"],\n",
    "                \"error\" : completion[\"error\"],\n",
    "                \"llm_output\" : completion[\"llm_output\"],\n",
    "            })\n",
    "            continue\n",
    "        completions.append({\n",
    "            \"invariants\": completion[\"annotations\"],\n",
    "            \"success\": completion[\"checker_output_for_annotations\"],\n",
    "            \"checker_message\": completion[\"checker_message_for_annotations\"],\n",
    "        })\n",
    "        if \"checker_output_after_prune\" in completion:\n",
    "            completions[-1][\"success_after_prune\"] = completion[\"checker_output_after_prune\"]\n",
    "            completions[-1][\"pruned_code\"] = completion[\"code_after_prune\"]\n",
    "    instance_json[\"completions\"] = completions\n",
    "    if \"code_after_prune\" in log:\n",
    "        instance_json[\"code_after_combine_and_prune\"] = log[\"code_after_prune\"]\n",
    "        instance_json[\"checker_output_after_combine_and_prune\"] = log[\"checker_output_after_prune\"]\n",
    "\n",
    "    combined_json[\"logs\"].append(instance_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in code2inv_file[\"logs\"]:\n",
    "    if \"completions\" not in log:\n",
    "        combined_json[\"files_to_rerun\"].append(log[\"file\"])\n",
    "        continue\n",
    "    instance_json = {\n",
    "        \"file\" : log[\"file\"],\n",
    "        \"benchmark_code\" : log[\"benchmark_code\"],\n",
    "        \"completions\" : log[\"completions\"],\n",
    "        \"invariants\" : log[\"invariants\"],\n",
    "        \"code_with_combined_invariants\" : log[\"code_with_combined_invariants\"],\n",
    "        \"checker_output\" : log[\"checker_output\"],\n",
    "    }\n",
    "    if \"code_after_combine_and_prune\" in log:\n",
    "        instance_json[\"code_after_combine_and_prune\"] = log[\"code_after_combine_and_prune\"]\n",
    "        instance_json[\"checker_output_after_combine_and_prune\"] = log[\"checker_output_after_combine_and_prune\"]\n",
    "\n",
    "    combined_json[\"logs\"].append(instance_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in zip(mix_benchmarks_file1[\"logs\"], mix_benchmarks_file2[\"logs\"]):\n",
    "    if \"completions\" not in log[0] or \"completions\" not in log[1]:\n",
    "        combined_json[\"files_to_rerun\"].append(log[0][\"file\"])\n",
    "        continue\n",
    "    instance_json = {\n",
    "        \"file\" : log[0][\"file\"],\n",
    "        \"benchmark_code\" : log[0][\"benchmark_code\"],\n",
    "        \"completions\" : log[0][\"completions\"] + log[1][\"completions\"],\n",
    "        \"invariants\" : log[0][\"invariants\"] + log[1][\"invariants\"],\n",
    "        \"code_with_combined_invariants\" : \"\",\n",
    "        \"checker_output\" : None,\n",
    "    }\n",
    "\n",
    "    combined_json[\"logs\"].append(instance_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt_4/combined_logs_m1_prompt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-3.5-Turbo logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
